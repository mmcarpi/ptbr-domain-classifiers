{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df770635-22b0-4cf0-9ca0-5e6af680e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import baycomp\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from config import ModelConfig\n",
    "from util import create_compute_metrics\n",
    "\n",
    "\n",
    "model_dir = Path(\"./Models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead19d45-67ed-4fc2-ab45-6a170bf2f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_metric(metric_name, metrics, int2model):\n",
    "    return np.array(\n",
    "        [[float(m[metric_name]) for m in metrics[int2model[i]]] for i in int2model]\n",
    "    ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa44e880-7e15-40f6-aefe-18871721e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(evals, num_samples, seed=42):\n",
    "    n = list(evals.values())[0].shape[0]\n",
    "    idx = list(range(n))\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "    sample_size = n // num_samples\n",
    "    evals = {\n",
    "        k: [\n",
    "            v[idx[i : i + sample_size]]\n",
    "            for i in range(0, sample_size * num_samples, sample_size)\n",
    "        ]\n",
    "        for k, v in evals.items()\n",
    "    }\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70f2c71-3106-4d9f-bb7d-3aca59fea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = create_compute_metrics(5, argmax_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c945d8-343d-44a9-ae4e-7092d88d7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = {}\n",
    "for root in Path(\"Models\").iterdir():\n",
    "    for model in root.iterdir():\n",
    "        evals[model.name] = pl.read_csv(model / \"eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0ef337-5ae6-4c26-931b-2c8ddb0e4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sample(evals, 50)\n",
    "metrics = {\n",
    "    \"-\".join(k.split(\"-\")[:2]): [\n",
    "        compute_metrics(y[\"y_pred\"].to_numpy(), y[\"y_true\"].to_numpy()) for y in v\n",
    "    ]\n",
    "    for k, v in s.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f8045c-997f-4799-9cde-ee9f2578c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2int = {m: i for i, m in enumerate(metrics.keys())}\n",
    "int2model = {i: m for m, i in models2int.items()}\n",
    "N = len(metrics[int2model[0]])\n",
    "M = len(models2int)\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6867b89a-f4cc-43cf-9388-c1a3c5002ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = [\"f1_micro\"]\n",
    "computed_metrics = {}\n",
    "for m in selected_metrics:\n",
    "    ys = select_metric(m, metrics, int2model)\n",
    "    computed_metrics[m] = [ys.mean(axis=0), ys.std(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f42e43-f240-4d39-9dcc-f1f643687aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(\n",
    "    [\"Entertainment\", \"Juridical\", \"Instructional\", \"Journalistic\", \"Virtual\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b293a85d-3adf-40eb-894f-a570ca3d6413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entertainment', 'Instructional', 'Journalistic', 'Juridical', 'Virtual']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d9bcd5-90f9-4911-b66b-d7135a75cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Entretenimento\", \"Instrucional\", \"Jornalístico\", \"Jurídico\", \"Virtual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38652bf-ab11-44be-b636-94902a18daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {\n",
    "    k: np.array(\n",
    "        compute_metrics(v[\"y_pred\"].to_numpy(), v[\"y_true\"].to_numpy())[\"cm\"]\n",
    "    ).reshape(len(labels), len(labels))\n",
    "    for k, v in evals.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259ffce9-419f-42d6-8c34-1ed7731fd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72d6502-bbb9-4afe-a2dd-ea108e881532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0235064-d3d4-44ca-b8c5-59701fca1b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.77988901, 0.72526457, 0.88504933, 0.87902018, 0.8761491 ,\n",
       "        0.87884417]),\n",
       " array([0.00311182, 0.00331462, 0.00223536, 0.00215734, 0.002282  ,\n",
       "        0.00217145])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_metrics[\"f1_micro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d3ef36-9bbc-4276-b77d-4a97d957b3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naive-bayes'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d16a7d7a-40e7-4a73-80d5-c027ece4b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svm'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f42d7e-46c7-4667-b570-11fde1a1bf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-large'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ea370d-7eaf-4bf0-b3e6-31d9dccf57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_name, title):\n",
    "    cmd = ConfusionMatrixDisplay(\n",
    "        cms[model_name],\n",
    "        display_labels=labels,\n",
    "    )\n",
    "    # plt.xticks(rotation=45)\n",
    "    # plt.figure(figsize=(20, 20))\n",
    "    disp = cmd.plot(values_format=\"d\", cmap=\"terrain\", text_kw={\"color\": \"black\"})\n",
    "    threshold = disp.im_.norm(disp.im_.get_clim()[1] * 0.5)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            # Use the cell value to determine its color from the colormap\n",
    "            cell_value = disp.confusion_matrix[i, j]\n",
    "\n",
    "            # Set text color to black or white based on the threshold\n",
    "            if disp.im_.norm(cell_value) > threshold:\n",
    "                disp.text_[i, j].set_color(\"black\")\n",
    "            else:\n",
    "                disp.text_[i, j].set_color(\"white\")\n",
    "\n",
    "    plt.xticks(fontsize=14, rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylabel(\"Domínio Verdadeiro\", fontsize=16)\n",
    "    plt.xlabel(\"Domínio Previsto\", fontsize=16)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    plt.savefig(f\"{model_name}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5958322-22a5-4930-8bc4-f84c68adab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_confusion_matrix(\"svm\", \"SVM\")\n",
    "plot_confusion_matrix(\"naive-bayes\", \"Naive Bayes\")\n",
    "plot_confusion_matrix(\"bert-large-portuguese-cased\", \"BERT Large\")\n",
    "plot_confusion_matrix(\"bert-base-portuguese-cased\", \"BERT Base\")\n",
    "plot_confusion_matrix(\"albertina-900m-portuguese-ptbr-encoder\", \"Albertina 900m\")\n",
    "plot_confusion_matrix(\"albertina-100m-portuguese-ptbr-encoder\", \"Albertina 100m\")\n",
    "!zip -r confusao.zip *.pdf && rm *.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f82624ec-2588-46cd-86d7-6f89c02ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringfy(metrics):\n",
    "    out = [f\"{metrics[0][i]:.3f} ({metrics[1][i]:.3f})\" for i in range(M)]\n",
    "    return out\n",
    "\n",
    "\n",
    "cols = dict(\n",
    "    models=[int2model[i] for i in range(M)],\n",
    "    **{k: stringfy(v) for k, v in computed_metrics.items()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68bd887b-ee42-401a-82a8-388769d1859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = pl.DataFrame(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b501ec-eed5-4d94-99e2-37b6966ede32",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs.write_csv(\"avgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1049ebce-3f0f-453c-b9eb-c2ba837d3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baycomp import SignedRankTest, SignTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de9cb5f7-988b-441d-88de-9063b6b53092",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\n",
    "def baycomp_latex_table(metric_name, *, highlight_color=\"EF8C40\"):\n",
    "    xs = select_metric(metric_name, metrics, int2model)\n",
    "    begin = \"\\\\begin{tabular}{@{}lllll@{}}\\\\hline\\n\\\\toprule\\n\"\n",
    "    center = lambda s: f\"\\\\multicolumn{{1}}{{c|}}{{{s}}}\"\n",
    "    rightr = lambda s: f\"\\\\multicolumn{{1}}{{r|}}{{{s}}}\"\n",
    "    lefter = lambda s: f\"\\\\multicolumn{{1}}{{l}}{{{s}}}\"\n",
    "    header = [\n",
    "        rightr(\"Modelo 1\"),\n",
    "        center(\"\\\\textgreater{}\"),\n",
    "        center(\"=\"),\n",
    "        center(\"\\\\textless{}\"),\n",
    "        lefter(\"Modelo 2\") + \"\\\\\\\\ \\\\midrule\\n\",\n",
    "    ]\n",
    "    header = (\n",
    "        f\"\\\\multicolumn{{5}}{{c}}{{{metric_name.title().replace('_', ' ')}}}\\\\\\\\ \\\\midrule\\n\"\n",
    "        + \" & \".join(header)\n",
    "    )\n",
    "\n",
    "    ism = (\n",
    "        lambda t, i: f\"\\\\cellcolor[HTML]{{{highlight_color}}}{t[i]:.2f}\"\n",
    "        if max(t) == t[i]\n",
    "        else f\"{t[i]:.2f}\"\n",
    "    )\n",
    "    create_row = (\n",
    "        lambda t: f\"%s & {center(ism(t, 0))} & {center(ism(t, 1))} & {center(ism(t, 2))} & %s\\\\\\\\\\n\"\n",
    "    )\n",
    "    end = f\"\\n\\\\end{{tabular}}\\n\"\n",
    "\n",
    "    output = begin + header\n",
    "    for i in range(M):\n",
    "        for j in range(i + 1, M):\n",
    "            t = SignedRankTest.probs(xs[:, i], xs[:, j], rope=0.001)\n",
    "            output += create_row(t) % (rightr(int2model[i]), lefter(int2model[j]))\n",
    "    output += end\n",
    "    return output\n",
    "\n",
    "\n",
    "for cm in computed_metrics.keys():\n",
    "    with open(cm + \".tex\", \"w\") as f:\n",
    "        f.write(baycomp_latex_table(cm))\n",
    "!zip -r tables.zip *.tex && rm *.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
