{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df770635-22b0-4cf0-9ca0-5e6af680e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import baycomp\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from config import ModelConfig\n",
    "from util import create_compute_metrics\n",
    "\n",
    "\n",
    "\n",
    "model_dir = Path(\"./Models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead19d45-67ed-4fc2-ab45-6a170bf2f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_metric(metric_name, metrics, int2model):\n",
    "    return np.array([[float(m[metric_name]) for m in metrics[int2model[i]]] for i in int2model]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa44e880-7e15-40f6-aefe-18871721e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(evals, num_samples, seed=42):\n",
    "    n = list(evals.values())[0].shape[0]\n",
    "    idx = list(range(n))\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "    sample_size = n // num_samples\n",
    "    evals = { k : [v[idx[i:i+sample_size]] for i in range(0, sample_size*num_samples, sample_size)] for k, v in evals.items()}\n",
    "    return evals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70f2c71-3106-4d9f-bb7d-3aca59fea7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics = create_compute_metrics(5, argmax_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c945d8-343d-44a9-ae4e-7092d88d7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = {}\n",
    "for root in Path(\"Models\").iterdir():\n",
    "    for model in root.iterdir():\n",
    "        evals[model.name] = pl.read_csv(model / 'eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0ef337-5ae6-4c26-931b-2c8ddb0e4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sample(evals, 50)\n",
    "metrics = { \n",
    "    '-'.join(k.split('-')[:2]) : [\n",
    "    compute_metrics(\n",
    "        y['y_pred'].to_numpy(),\n",
    "        y['y_true'].to_numpy()) for y in v\n",
    "    ] for k, v in s.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f8045c-997f-4799-9cde-ee9f2578c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2int = {m : i for i, m in enumerate(metrics.keys()) }\n",
    "int2model = { i :  m for m, i in models2int.items()}\n",
    "N = len(metrics[int2model[0]])\n",
    "M = len(models2int)\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6867b89a-f4cc-43cf-9388-c1a3c5002ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_metrics = ['f1_micro']\n",
    "computed_metrics = {}\n",
    "for m in selected_metrics:\n",
    "    ys = select_metric(m, metrics, int2model)\n",
    "    computed_metrics[m] = [ys.mean(axis=0), ys.std(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38652bf-ab11-44be-b636-94902a18daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = { k : np.array(compute_metrics(v['y_pred'].to_numpy(), v['y_true'].to_numpy())['cm']).reshape(M, M) for k, v in evals.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259ffce9-419f-42d6-8c34-1ed7731fd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72d6502-bbb9-4afe-a2dd-ea108e881532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f42e43-f240-4d39-9dcc-f1f643687aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted([\"Entertainment\", \"Juridical\", \"Instructional\", \"Journalistic\", \"Virtual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0235064-d3d4-44ca-b8c5-59701fca1b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7313722 , 0.88504933, 0.87902018, 0.8761491 , 0.87884417]),\n",
       " array([0.00303537, 0.00223536, 0.00215734, 0.002282  , 0.00217145])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_metrics['f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ea370d-7eaf-4bf0-b3e6-31d9dccf57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_name, title):\n",
    "    cmd = ConfusionMatrixDisplay(\n",
    "        cms[model_name],\n",
    "        display_labels=labels,\n",
    "    )\n",
    "    #plt.xticks(rotation=45)\n",
    "    #plt.figure(figsize=(20, 20))\n",
    "    disp = cmd.plot(values_format='d', cmap='terrain')\n",
    "    plt.xticks(fontsize=14, rotation=45)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.ylabel('Domínio Verdadeiro', fontsize=16)\n",
    "    plt.xlabel('Domínio Previsto', fontsize=16)\n",
    "    plt.title(title, fontsize=18)\n",
    " \n",
    "    plt.savefig(f'{model_name}.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5958322-22a5-4930-8bc4-f84c68adab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "plot_confusion_matrix('naive-bayes', 'Naive Bayes')\n",
    "plot_confusion_matrix('bert-large-portuguese-cased', 'BERT Large')\n",
    "plot_confusion_matrix('bert-base-portuguese-cased', 'BERT Base')\n",
    "plot_confusion_matrix('albertina-900m-portuguese-ptbr-encoder', 'Albertina 900m')\n",
    "plot_confusion_matrix('albertina-100m-portuguese-ptbr-encoder', 'Albertina 100m')\n",
    "!zip -r confusao.zip *.pdf && rm *.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f82624ec-2588-46cd-86d7-6f89c02ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringfy(metrics):\n",
    "    out = [f\"{metrics[0][i]:.3f} ({metrics[1][i]:.3f})\" for i in range(M)]\n",
    "    return out\n",
    "\n",
    "cols = dict(\n",
    "    models=[int2model[i] for i in range(M)],\n",
    "    **{ k : stringfy(v) for k, v in computed_metrics.items()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68bd887b-ee42-401a-82a8-388769d1859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = pl.DataFrame(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b501ec-eed5-4d94-99e2-37b6966ede32",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs.write_csv(\"avgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1049ebce-3f0f-453c-b9eb-c2ba837d3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baycomp import SignedRankTest, SignTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de9cb5f7-988b-441d-88de-9063b6b53092",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def baycomp_latex_table(metric_name, *, highlight_color=\"EF8C40\"):\n",
    "    xs = select_metric(metric_name, metrics, int2model)\n",
    "    begin = \"\\\\begin{tabular}{@{}lllll@{}}\\\\hline\\n\\\\toprule\\n\"\n",
    "    center = lambda s: f\"\\\\multicolumn{{1}}{{c|}}{{{s}}}\"\n",
    "    rightr = lambda s: f\"\\\\multicolumn{{1}}{{r|}}{{{s}}}\"\n",
    "    lefter = lambda s: f\"\\\\multicolumn{{1}}{{l}}{{{s}}}\"\n",
    "    header = [\n",
    "        rightr('Modelo 1'),\n",
    "        center('\\\\textgreater{}'),\n",
    "        center('='),\n",
    "        center('\\\\textless{}'),\n",
    "        lefter('Modelo 2') + '\\\\\\\\ \\\\midrule\\n'\n",
    "    ]\n",
    "    header = f\"\\\\multicolumn{{5}}{{c}}{{{metric_name.title().replace('_', ' ')}}}\\\\\\\\ \\\\midrule\\n\" + ' & '.join(header)\n",
    "\n",
    "    ism = lambda t, i: f\"\\\\cellcolor[HTML]{{{highlight_color}}}{t[i]:.2f}\" if max(t) == t[i] else f\"{t[i]:.2f}\"\n",
    "    create_row = lambda t: f\"%s & {center(ism(t, 0))} & {center(ism(t, 1))} & {center(ism(t, 2))} & %s\\\\\\\\\\n\"\n",
    "    end = f\"\\n\\\\end{{tabular}}\\n\"\n",
    "\n",
    "    output = begin + header\n",
    "    for i in range(M):\n",
    "        for j in range(i+1, M):\n",
    "            t = SignedRankTest.probs(xs[:, i], xs[:, j], rope=0.001)\n",
    "            output += create_row(t) % (rightr(int2model[i]), lefter(int2model[j]))\n",
    "    output += end\n",
    "    return output\n",
    "\n",
    "for cm in computed_metrics.keys():\n",
    "    with open(cm+'.tex', 'w') as f:\n",
    "        f.write(baycomp_latex_table(cm))\n",
    "!zip -r tables.zip *.tex && rm *.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
